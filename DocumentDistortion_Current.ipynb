{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sungulnara2000/DocumentDistortion/blob/main/DocumentDistortion_Current.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U98Bwy9lPhTY"
      },
      "source": [
        "### Установка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ONm8Xm5ZuK7_",
        "outputId": "06df452c-c070-4811-868c-f079ef5815b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 154 kB of archives.\n",
            "After this operation, 613 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 poppler-utils amd64 0.62.0-2ubuntu2.12 [154 kB]\n",
            "Fetched 154 kB in 0s (891 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 155455 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.62.0-2ubuntu2.12_amd64.deb ...\n",
            "Unpacking poppler-utils (0.62.0-2ubuntu2.12) ...\n",
            "Setting up poppler-utils (0.62.0-2ubuntu2.12) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-poppler"
      ],
      "metadata": {
        "id": "p7q9em08tuUm",
        "outputId": "131f5c99-89e3-4d79-9fce-e7e0d0115247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-poppler\n",
            "  Downloading python-poppler-0.3.0.tar.gz (823 kB)\n",
            "\u001b[K     |████████████████████████████████| 823 kB 4.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: python-poppler\n",
            "  Building wheel for python-poppler (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for python-poppler\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for python-poppler\n",
            "Failed to build python-poppler\n",
            "Installing collected packages: python-poppler\n",
            "    Running setup.py install for python-poppler ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-57xvd3_i/python-poppler_3b5840b57e644a18871bc10443cb2422/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-57xvd3_i/python-poppler_3b5840b57e644a18871bc10443cb2422/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-7nudb39a/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/python-poppler Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss2lDTsA1VgP"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-contrib-python==3.4.2.17\n",
        "!pip install -U plotly==4.12\n",
        "!pip install pyheif Pillow\n",
        "!pip install pdf2image\n",
        "!apt-get install poppler-utils "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4zDNJG1L9LS_"
      },
      "outputs": [],
      "source": [
        "def sin(angle):\n",
        "  return np.sin(np.deg2rad(angle))\n",
        "\n",
        "def cos(angle):\n",
        "  return np.cos(np.deg2rad(angle))\n",
        "\n",
        "def rint(x):\n",
        "  ret = np.rint(x).astype(int)\n",
        "  if type(x) == tuple:\n",
        "    ret = tuple(ret)\n",
        "  return ret\n",
        "\n",
        "def int_tuple(l):\n",
        "  return tuple(map(int, l))\n",
        "\n",
        "def nearest_odd(x):\n",
        "    return int(np.ceil(x) // 2 * 2 + 1)\n",
        "\n",
        "\n",
        "def reduce_in_size(image, n):\n",
        "  return cv.resize(image, (rint(image.shape[1] / n), rint(image.shape[0] / n)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ll0tPr3OlW6Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "from os import path\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.spatial import distance\n",
        "from PIL import Image\n",
        "import pyheif\n",
        "import glob\n",
        "from scipy.optimize import brentq\n",
        "from tqdm import tqdm\n",
        "\n",
        "from scipy import interpolate\n",
        "\n",
        "import pdf2image\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8Tf9SGAkoWw",
        "outputId": "83d7aa32-762d-4bdf-b614-9672bc4c238e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FCpCGuAhB7_j"
      },
      "outputs": [],
      "source": [
        "def conv_heic2png(image_path, delete=False):\n",
        "    new_name = image_path.replace('HEIC', 'png')\n",
        "    heif_file = pyheif.read(image_path)\n",
        "    data = Image.frombytes(\n",
        "        heif_file.mode,\n",
        "        heif_file.size,\n",
        "        heif_file.data,\n",
        "        \"raw\",\n",
        "        heif_file.mode,\n",
        "        heif_file.stride,\n",
        "        )\n",
        "    data.save(new_name, \"PNG\")\n",
        "    if delete:\n",
        "      os.remove(image_path)\n",
        "\n",
        "def heic2png(path, delete=False):\n",
        "  lst = glob.glob(f\"{path}/*.HEIC\")\n",
        "  for l in lst:\n",
        "      conv_heic2png(l, delete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "76GXCaCdcyJn"
      },
      "outputs": [],
      "source": [
        "SAMPLES_FOLDER = '/content/drive/MyDrive/paper_distortions'\n",
        "RESULTS_FOLDER = os.path.join(SAMPLES_FOLDER, 'results')\n",
        "CRUMPLED_RESULTS_FOLDER = os.path.join(SAMPLES_FOLDER, 'crumpled_results')\n",
        "EDOCS_FOLDER = os.path.join(SAMPLES_FOLDER, 'electronic_documents')\n",
        "EDOCS_PDF_FOLDER = os.path.join(SAMPLES_FOLDER, 'pdfs')\n",
        "\n",
        "PDF_DPI = 400\n",
        "\n",
        "N_DOTS_ROW = 21\n",
        "N_DOTS_COL = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhv7VGtSU-Ys"
      },
      "outputs": [],
      "source": [
        "heic2png(SAMPLES_FOLDER, delete=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm $EDOCS_FOLDER/*"
      ],
      "metadata": {
        "id": "KmR_SkVqzH7G"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfs = os.listdir(EDOCS_PDF_FOLDER)\n",
        "for filename in pdfs:\n",
        "  basename = filename.split('.')[0]\n",
        "  pdf2image.convert_from_path(os.path.join(EDOCS_PDF_FOLDER, filename), \n",
        "                              dpi=PDF_DPI, \n",
        "                              output_folder=EDOCS_FOLDER,\n",
        "                              fmt='png',\n",
        "                              output_file=f'{basename}_dpi_{PDF_DPI}')"
      ],
      "metadata": {
        "id": "oeH7_bSkrfef"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeSXYRXZarAd"
      },
      "source": [
        "# Детекция точек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JW8DrcQfPBA6"
      },
      "outputs": [],
      "source": [
        "CIRCLE_N = 32\n",
        "reference_circle = np.ones((CIRCLE_N, CIRCLE_N), np.uint8) * 255\n",
        "reference_circle = cv.circle(reference_circle, \n",
        "                             rint((CIRCLE_N/2, CIRCLE_N/2)), \n",
        "                             rint(CIRCLE_N/5), \n",
        "                             color=(0, 0, 0), \n",
        "                             thickness=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "WoF4YglTROMp",
        "outputId": "6f8bdcbc-5990-4e26-a790-ac0e37f07b4d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F8B1E41B5D0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAACeElEQVR4nN2WsWvqUBTGP4uVFjRB6qVukVYocX/LGxW6NEKnrgpuLZ30zygtxdH/oMtzLujWpbMGoUsCrSiRklsXCdXzBuUZk9yoj3Z479vy3ZPzS87JzT0RIsJ3audbs/8XgOiGcZMJHAecw7LAGGQZsRj29r4C8PGBhwc0mzBNvL/DcbC7i4MDKArOz3FxAUkKuz0S8hXNZnh8xPU1Pj+Rz4Mx7O+jXsflJRwHoxFaLUSjqNdxeoodUbFJrFqNGKNymQxj4Tw/0+EhPT0tLg2DSiVijKpVYRIhoFgkWSZdXzE9gLl0nRIJ0rTgPAEvNpuhWISu4/UVqrq2R1BV9PvQdWgaZjPvagDg/h6dDlotxOMB6YbDod+Mx9Fuo9PB3d26HnBO2SxVKr5SLvQDGAA/A++tVCibJc5De9BoUCaz7Opqdi/AwzAMymSo0RD3YDJBs4lCAYqyNCORSEClglYVBfk8mk1MJsuAFYDjwDSRSoUkXCPGYJpwHAGAc9j2Rl+OSKoK2wbnAoBlIZnEycnS8dWnD/wC3tyWOyaXQzKJwUAAYAyc4+Vl6ZD3R/IGXAGm23LH9HrgHOm0ACDLkCR0uwiVby+51O1CkiDLAkAsBkWBZYUDwjQaQVEQi7msLfeBV2v3wbY7WZidNtzJRHRzQ4rifQk3KdCfP/7trS/eHzqd0tkZHR3ReBzM8Gs8puNj0jSaTjcAzKVplEh4z4NA6TrJMhWLwathJ1q1SoxRqSQsl2FQuUyMUa0mTLLpmVwoIJWCqiKXQ6+HbheWhXZ7/ZkcBpjLPVXYNpJJcA5J+oqpwq0/c9FggHR6i7loU8Bf69+fTX8DAhy9xQ6LMUIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "surf = cv.xfeatures2d.SURF_create(hessianThreshold=700, nOctaves=2, nOctaveLayers=2, upright=True)\n",
        "reference_circle_kp, reference_circle_des = surf.detectAndCompute(reference_circle, None)\n",
        "img_surf = cv.drawKeypoints(reference_circle, reference_circle_kp, None,(255,0,0),4)\n",
        "cv2_imshow(img_surf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qvSRYNcyhAk7"
      },
      "outputs": [],
      "source": [
        "def intersection_area(d, R, r):\n",
        "    \"\"\"Return the area of intersection of two circles.\n",
        "\n",
        "    The circles have radii R and r, and their centres are separated by d.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if d <= abs(R-r):\n",
        "        # One circle is entirely enclosed in the other.\n",
        "        return np.pi * min(R, r)**2\n",
        "    if d >= r + R:\n",
        "        # The circles don't overlap at all.\n",
        "        return 0\n",
        "\n",
        "    r2, R2, d2 = r**2, R**2, d**2\n",
        "    alpha = np.arccos((d2 + r2 - R2) / (2*d*r))\n",
        "    beta = np.arccos((d2 + R2 - r2) / (2*d*R))\n",
        "    return ( r2 * alpha + R2 * beta -\n",
        "             0.5 * (r2 * np.sin(2*alpha) + R2 * np.sin(2*beta))\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "z-jtmnbKbMbM"
      },
      "outputs": [],
      "source": [
        "def iou_key_points(kp_one, kp_two):\n",
        "  distance_between_centers = np.linalg.norm(np.array(kp_one.pt) - np.array(kp_two.pt))\n",
        "  intersection = intersection_area(distance_between_centers, kp_one.size, kp_two.size)\n",
        "  area_one = np.pi * kp_one.size ** 2\n",
        "  area_two = np.pi * kp_two.size ** 2\n",
        "  return intersection / (area_one + area_two - intersection)\n",
        "\n",
        "def delete_similar_key_points(kp, iou_threshold):\n",
        "  \"\"\"\n",
        "  Note that kp should be passed in descending response order (as from detectAndCompute)\n",
        "  \"\"\"\n",
        "  assert sorted(kp, key=lambda x: -x.response) == kp\n",
        "\n",
        "  new_kp = []\n",
        "  indices = []\n",
        "\n",
        "  for i, point in enumerate(kp):\n",
        "    discard = False\n",
        "    for compare_point in kp:\n",
        "      if iou_key_points(point, compare_point) >= iou_threshold:\n",
        "        if compare_point.response > point.response:\n",
        "          discard = True\n",
        "    if not discard:\n",
        "      new_kp.append(point)\n",
        "      indices.append(i)\n",
        "\n",
        "  return new_kp, indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHtCcGemPx3R",
        "outputId": "e4d44854-8d9f-4cb5-d91c-b0d45b21da9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2189.21533203125, 2634.302978515625)\n"
          ]
        }
      ],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, 'IMG_1436.png'))\n",
        "img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "surf = cv.xfeatures2d.SURF_create(hessianThreshold=1500, upright=True)\n",
        "\n",
        "img_blur = cv.GaussianBlur(img, (15, 15), 0)\n",
        "\n",
        "# cv2_imshow(img_blur)\n",
        "kp, des = surf.detectAndCompute(img_blur, None)\n",
        "\n",
        "print(kp[0].pt)\n",
        "\n",
        "img_surf = cv.drawKeypoints(img, kp, None,(255,0,0), 4)\n",
        "# cv2_imshow(cv.resize(img_surf, (rint(img_surf.shape[1] / 2), rint(img_surf.shape[0] / 2))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMaqDZRXnEW5"
      },
      "outputs": [],
      "source": [
        "new_kp, indices = delete_similar_key_points(kp, iou_threshold=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya7CA1CxnS9L",
        "outputId": "f2603363-71f5-4153-b5f4-4d5302bbebb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1412, 692)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(kp), len(new_kp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-A7rRWnuJkN"
      },
      "outputs": [],
      "source": [
        "new_des = des[indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ee3jzjonVvK"
      },
      "outputs": [],
      "source": [
        "img_surf = cv.drawKeypoints(img, new_kp, None,(255,0,0), 4)\n",
        "cv2_imshow(cv.resize(img_surf, (rint(img_surf.shape[1] / 2), rint(img_surf.shape[0] / 2))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Oc9-7hmnxp3"
      },
      "outputs": [],
      "source": [
        "circle_kp = sorted(list(zip(new_kp, new_des)), key=lambda x: np.linalg.norm(x[1] - reference_circle_des))\n",
        "circle_kp = [x[0] for x in circle_kp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG6XnvEcfpPn"
      },
      "outputs": [],
      "source": [
        "img_surf = cv.drawKeypoints(img, circle_kp[:N_DOTS_ROW * N_DOTS_COL], None, (255, 0, 0), 4)\n",
        "cv2_imshow(cv.resize(img_surf, (rint(img_surf.shape[1] / 2), rint(img_surf.shape[0] / 2))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVV3YvaTQjnw"
      },
      "outputs": [],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, 'IMG_1443.png'))\n",
        "\n",
        "# convert img to grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# blur image\n",
        "blur = cv.GaussianBlur(gray, (9,9), 0)\n",
        "\n",
        "# do otsu threshold on gray image\n",
        "thresh = cv.adaptiveThreshold(blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 77, 33)\n",
        "# thresh = cv.threshold(blur, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1]\n",
        "\n",
        "# apply morphology\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
        "# kernel = np.ones((9,9), np.uint8)\n",
        "morph = cv.morphologyEx(morph, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "# cv2_imshow(blur)\n",
        "cv2_imshow(thresh)\n",
        "cv2_imshow(morph)\n",
        "\n",
        "# get largest contour\n",
        "contours = cv.findContours(morph, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "big_contour = max(contours, key = cv.contourArea)\n",
        "\n",
        "countour_img = cv.drawContours(img, [big_contour], 0, (0,255,0), 3)\n",
        "# cv2_imshow(countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8glnQJhkDfn"
      },
      "outputs": [],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, 'IMG_1435.png'))\n",
        "\n",
        "# convert img to grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# blur image\n",
        "blur = cv.GaussianBlur(gray, (9,9), 0)\n",
        "\n",
        "# do otsu threshold on gray image\n",
        "thresh = cv.adaptiveThreshold(blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 77, 33)\n",
        "# thresh = cv.threshold(blur, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1]\n",
        "\n",
        "# apply morphology\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
        "morph = cv.morphologyEx(morph, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "# cv2_imshow(blur)\n",
        "cv2_imshow(thresh)\n",
        "cv2_imshow(morph)\n",
        "\n",
        "# get largest contour\n",
        "contours = cv.findContours(morph, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "big_contour = max(contours, key = cv.contourArea)\n",
        "\n",
        "countour_img = cv.drawContours(img, [big_contour], 0, (0,255,0), 3)\n",
        "# cv2_imshow(countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8X4Yc3ibSU_"
      },
      "outputs": [],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, 'IMG_1435.png'))\n",
        "\n",
        "# convert img to grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# blur image\n",
        "blur = cv.GaussianBlur(gray, (9,9), 0)\n",
        "\n",
        "# do otsu threshold on gray image\n",
        "thresh = cv.adaptiveThreshold(blur,255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, nearest_odd(blur.shape[0] / 100), 5)\n",
        "# thresh = cv.threshold(blur, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1]\n",
        "\n",
        "# apply morphology\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
        "morph = cv.morphologyEx(morph, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "# cv2_imshow(blur)\n",
        "cv2_imshow(thresh)\n",
        "cv2_imshow(morph)\n",
        "\n",
        "# get largest contour\n",
        "contours = cv.findContours(morph, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "big_contour = max(contours, key = cv.contourArea)\n",
        "\n",
        "countour_img = cv.drawContours(img, [big_contour], 0, (0,255,0), 3)\n",
        "# cv2_imshow(countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSmS1yJugnZR",
        "outputId": "7bf70af4-8071-434a-f6e2-9a761043d3ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nearest_odd(blur.shape[0] / 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlyLO5s9cG4t"
      },
      "outputs": [],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, 'IMG_1435.png'))\n",
        "\n",
        "# convert img to grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# blur image\n",
        "blur = cv.GaussianBlur(gray, (11,11), 0)\n",
        "\n",
        "# do otsu threshold on gray image\n",
        "thresh = cv.adaptiveThreshold(blur,255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 41, 5)\n",
        "\n",
        "# apply morphology\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
        "kernel = np.ones((7, 7), np.uint8)\n",
        "morph = cv.morphologyEx(morph, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "cv2_imshow(blur)\n",
        "cv2_imshow(thresh)\n",
        "cv2_imshow(morph)\n",
        "\n",
        "# get largest contour\n",
        "contours = cv.findContours(morph, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "big_contour = max(contours, key = cv.contourArea)\n",
        "\n",
        "countour_img = cv.drawContours(img, [big_contour], 0, (0,255,0), 3)\n",
        "# cv2_imshow(countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Dko1FLcLeo",
        "outputId": "ce6002af-adbe-463c-bb46-6b7352a8473e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1.0, 550.9863882166237)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv.pointPolygonTest(big_contour, (2000, 2000), measureDist=False), cv.pointPolygonTest(big_contour, (2000, 2000), measureDist=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydXXWwd3bSiU",
        "outputId": "c8fc3a9b-bdeb-40a5-f3bd-7ceaf7b43826"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(-1.0, -477.3782567314938)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv.pointPolygonTest(big_contour, (0, 0), measureDist=False), cv.pointPolygonTest(big_contour, (0, 0), measureDist=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ezDkcUcW4B",
        "outputId": "b3f904e5-839f-43d1-b266-89b26298c6b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6a2e56bf-11e1-4cd0-aef1-3d628d49c458-2.jpg  IMG_1446.png\n",
            "alined.jpg\t\t\t\t    IMG_1447.png\n",
            "electronic_documents\t\t\t    IMG_1449.png\n",
            "IMG_1435.png\t\t\t\t    IMG-20211130-WA0067-2.jpg\n",
            "IMG_1436.png\t\t\t\t    IMG-20211130-WA0067.jpg\n",
            "IMG_1438.png\t\t\t\t    IMG-20211130-WA0069-2.jpg\n",
            "IMG_1439.png\t\t\t\t    IMG-20211130-WA0069.jpg\n",
            "IMG_1441.png\t\t\t\t    photo_2021-12-26_19-00-26.jpg\n",
            "IMG_1442.png\t\t\t\t    qXYn5.jpg\n",
            "IMG_1443.png\t\t\t\t    red_blue_dots_a4_2480_3508.png\n",
            "IMG_1445.png\n"
          ]
        }
      ],
      "source": [
        "!ls $SAMPLES_FOLDER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsUgCihSdy56"
      },
      "outputs": [],
      "source": [
        "surf = cv.xfeatures2d.SIFT_create(hessianThreshold=700, nOctaves=2, nOctaveLayers=2, upright=True)\n",
        "\n",
        "img_blur = cv.GaussianBlur(img, (15, 15), 0)\n",
        "cv2_imshow(img_blur)\n",
        "kp, des = surf.detectAndCompute(img_blur, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGx3aNNxpvK0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-HY8OnGpvsN"
      },
      "source": [
        "# Удаление маркеров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN0wZkmEqQlF"
      },
      "outputs": [],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, 'IMG_1436.png'))\n",
        "\n",
        "# convert img to grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# blur image\n",
        "blur = cv.GaussianBlur(gray, (9,9), 0)\n",
        "\n",
        "# do otsu threshold on gray image\n",
        "thresh = cv.adaptiveThreshold(blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 77, 33)\n",
        "# thresh = cv.threshold(blur, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1]\n",
        "\n",
        "# apply morphology\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
        "morph = cv.morphologyEx(morph, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "cv2_imshow(morph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qMPVTgOXeCV"
      },
      "outputs": [],
      "source": [
        "countour_img = cv.drawContours(img, contours, -1, (0,255,0), 3)\n",
        "cv2_imshow(countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4CX6FosYSlc"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(morph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khDUZvkRZl8b"
      },
      "outputs": [],
      "source": [
        "contours = cv.findContours(morph, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoqUHDidZm3K",
        "outputId": "3a4d2888-b3a4-413f-999d-dc0f27a15c76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(contours[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvQnC5hmZ54x"
      },
      "outputs": [],
      "source": [
        "big_contour = max(contours[1], key = cv.contourArea)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PRO96Ttdwj9"
      },
      "outputs": [],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, 'IMG_1442.png'))\n",
        "contour_image = cv.drawContours(img, [big_contour], 0, (0,255,0), 3)\n",
        "cv2_imshow(cv.resize(contour_image, (1512, 2016)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sFhjEBIZvJR"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(cv.drawContours(img, contours[1], -1, (0,255,0), 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmZJkmiiL1Sm"
      },
      "outputs": [],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, 'IMG_1442.png'))\n",
        "\n",
        "\n",
        "# convert img to grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# blur image\n",
        "blur = cv.GaussianBlur(gray, (9,9), 0)\n",
        "\n",
        "# do otsu threshold on gray image\n",
        "# thresh = cv.adaptiveThreshold(blur,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, nearest_odd(blur.shape[0] / 100), 5)\n",
        "thresh = cv.threshold(blur, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1]\n",
        "\n",
        "# apply morphology\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "thresh = thresh\n",
        "morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
        "morph = cv.morphologyEx(morph, cv.MORPH_OPEN, kernel)\n",
        "# kernel = np.ones((3,3), np.uint8)\n",
        "# morph = cv.erode(morph, kernel, iterations=1)\n",
        "\n",
        "# cv2_imshow(blur)\n",
        "# cv2_imshow(thresh)\n",
        "# cv2_imshow(morph)\n",
        "\n",
        "# get largest contour\n",
        "contours = cv.findContours(morph, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "big_contour = max(contours, key = cv.contourArea)\n",
        "\n",
        "countour_img = cv.drawContours(img, [big_contour], 0, (0,255,0), 3)\n",
        "# cv2_imshow(countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB57U2iKNNWH"
      },
      "outputs": [],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, 'IMG_1442.png'))\n",
        "\n",
        "\n",
        "# convert img to grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# blur image\n",
        "blur = cv.GaussianBlur(gray, (9,9), 0)\n",
        "\n",
        "# do otsu threshold on gray image\n",
        "thresh = cv.adaptiveThreshold(blur,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, nearest_odd(blur.shape[0] / 100), 5)\n",
        "\n",
        "# apply morphology\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
        "morph = cv.morphologyEx(morph, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "# cv2_imshow(blur)\n",
        "# cv2_imshow(thresh)\n",
        "# cv2_imshow(morph)\n",
        "\n",
        "# get largest contour\n",
        "contours = cv.findContours(morph, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "big_contour = max(contours, key = cv.contourArea)\n",
        "\n",
        "countour_img = cv.drawContours(img, [big_contour], 0, (0,255,0), 3)\n",
        "cv2_imshow(countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98tyfldgMDnW"
      },
      "outputs": [],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, 'IMG_1436.png'))\n",
        "\n",
        "\n",
        "# convert img to grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# blur image\n",
        "blur = cv.GaussianBlur(gray, (9,9), 0)\n",
        "\n",
        "# do otsu threshold on gray image\n",
        "thresh = cv.adaptiveThreshold(blur,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, nearest_odd(blur.shape[0] / 100), 5)\n",
        "\n",
        "# apply morphology\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
        "morph = cv.morphologyEx(morph, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "# cv2_imshow(blur)\n",
        "# cv2_imshow(thresh)\n",
        "cv2_imshow(morph)\n",
        "\n",
        "# get largest contour\n",
        "contours = cv.findContours(morph, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "big_contour = max(contours, key = cv.contourArea)\n",
        "\n",
        "countour_img = cv.drawContours(img, [big_contour], 0, (0,255,0), 3)\n",
        "cv2_imshow(countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW7Z6IwwKSN7"
      },
      "outputs": [],
      "source": [
        "# do otsu threshold on gray image\n",
        "thresh = cv.adaptiveThreshold(blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, nearest_odd(blur.shape[0] / 100), 5)\n",
        "\n",
        "# apply morphology\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
        "morph = cv.morphologyEx(morph, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "# cv2_imshow(blur)\n",
        "# cv2_imshow(thresh)\n",
        "# cv2_imshow(morph)\n",
        "\n",
        "# get largest contour\n",
        "image, contours, hierarchy = cv.findContours(morph, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "# contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "# big_contour = max(contours, key = cv.contourArea)\n",
        "\n",
        "# countour_img = cv.drawContours(img, contours, 0, (0,255,0), 3)\n",
        "# cv2_imshow(countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGZfdd-1Ltfc"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(morph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEBO0y4-J7fN"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOdJKbvutykN"
      },
      "outputs": [],
      "source": [
        "kernel = np.ones((7,7), np.uint8)\n",
        "dilated = cv.dilate(255 - morph, kernel, iterations=1)\n",
        "cv2_imshow(dilated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqSqZ0tMxut2"
      },
      "outputs": [],
      "source": [
        "dst = cv.inpaint(img, dilated, 30, cv.INPAINT_TELEA)\n",
        "cv2_imshow(dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FldEKxYitL8c"
      },
      "outputs": [],
      "source": [
        "dst = cv.inpaint(img, dilated, 3, cv.INPAINT_TELEA)\n",
        "cv2_imshow(dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCUE4mFeugg9"
      },
      "outputs": [],
      "source": [
        "dst = cv.inpaint(img, dilated, 3, cv.INPAINT_NS)\n",
        "cv2_imshow(dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1amuLA0D5WeL"
      },
      "source": [
        "# Сохранение результатов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSvqKvhrnQHL"
      },
      "source": [
        "Протестированы:  \n",
        "<!-- IMG_1436   -->\n",
        "IMG_1446  \n",
        "IMG_3256  \n",
        "3267"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vw1oXnsLqikl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $SAMPLES_FOLDER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN7f6lPMtQoP",
        "outputId": "fa719e88-8cc0-46e5-80e4-f480d8f297a8"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 6a2e56bf-11e1-4cd0-aef1-3d628d49c458-2.jpg   IMG_3253.png\n",
            " alined.jpg\t\t\t\t      IMG_3254.png\n",
            " electronic_documents\t\t\t      IMG_3255.png\n",
            " IMG_1435.png\t\t\t\t      IMG_3256.png\n",
            " IMG_1436.png\t\t\t\t      IMG_3257.png\n",
            " IMG_1438.png\t\t\t\t      IMG_3258.png\n",
            " IMG_1439.png\t\t\t\t      IMG_3259.png\n",
            " IMG_1441.png\t\t\t\t      IMG_3260.png\n",
            " IMG_1442.png\t\t\t\t      IMG_3261.png\n",
            " IMG_1443.png\t\t\t\t      IMG_3262.png\n",
            " IMG_1445.png\t\t\t\t      IMG_3263.png\n",
            " IMG_1446.png\t\t\t\t      IMG_3264.png\n",
            " IMG_1447.jpg\t\t\t\t      IMG_3265.png\n",
            " IMG_1447.png\t\t\t\t      IMG_3266.png\n",
            " IMG_1449.png\t\t\t\t      IMG_3267.png\n",
            " IMG-20211130-WA0067-2.jpg\t\t      IMG_3268.png\n",
            " IMG-20211130-WA0067.jpg\t\t      IMG_3269.png\n",
            " IMG-20211130-WA0069-2.jpg\t\t      IMG_3270.png\n",
            " IMG-20211130-WA0069.jpg\t\t      IMG_3271.png\n",
            " IMG_3248.png\t\t\t\t      photo_2021-12-26_19-00-26.jpg\n",
            " IMG_3249.png\t\t\t\t      qXYn5.jpg\n",
            " IMG_3250.png\t\t\t\t      red_blue_dots_a4_2480_3508.png\n",
            " IMG_3251.png\t\t\t\t      results\n",
            " IMG_3252.png\t\t\t\t     'Копия IMG_1447.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(*[x for x in os.listdir(RESULTS_FOLDER) if 'transformed_shadows_' in x], end=\"' '\", sep=\"' '\")"
      ],
      "metadata": {
        "id": "nBSfi4l8xcSI",
        "outputId": "5e8263e0-d914-47ff-f659-75d6ce0772f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformed_shadows_mult_IMG_3267_Diagram description (2)_page-0001.png' 'transformed_shadows_alpha_IMG_3267_Diagram description (2)_page-0001.png' 'transformed_shadows_alpha_IMG_1443_Article Multisensory marketing (senses)_page-0001.png' 'transformed_shadows_mult_IMG_1443_Article Multisensory marketing (senses)_page-0001.png' 'transformed_shadows_alpha_IMG_1446_pervichnye_dokumenty_buhgalterskogo_ucheta_3.png' 'transformed_shadows_mult_IMG_1446_pervichnye_dokumenty_buhgalterskogo_ucheta_3.png' 'transformed_shadows_alpha_IMG_1446_Article Multisensory marketing (senses)_page-0001.png' 'transformed_shadows_mult_IMG_1446_Article Multisensory marketing (senses)_page-0001.png' 'transformed_shadows_alpha_IMG_3264_Article Multisensory marketing (senses)_page-0002.png' 'transformed_shadows_mult_IMG_3264_Article Multisensory marketing (senses)_page-0002.png' 'transformed_shadows_alpha_IMG_3266_report_finance.png' 'transformed_shadows_mult_IMG_3266_report_finance.png' '"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "dc3ZGt_D0Szp",
        "outputId": "55ca7c91-a720-479a-ce86-95ce517a6528",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# os.chdir('RESULTS_FOLDER')"
      ],
      "metadata": {
        "id": "nuzSFlEGyN_V"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp 'transformed_shadows_mult_IMG_3267_Diagram description (2)_page-0001.png' 'transformed_shadows_alpha_IMG_3267_Diagram description (2)_page-0001.png' 'transformed_shadows_alpha_IMG_1443_Article Multisensory marketing (senses)_page-0001.png' 'transformed_shadows_mult_IMG_1443_Article Multisensory marketing (senses)_page-0001.png' 'transformed_shadows_alpha_IMG_1446_pervichnye_dokumenty_buhgalterskogo_ucheta_3.png' 'transformed_shadows_mult_IMG_1446_pervichnye_dokumenty_buhgalterskogo_ucheta_3.png' 'transformed_shadows_alpha_IMG_1446_Article Multisensory marketing (senses)_page-0001.png' 'transformed_shadows_mult_IMG_1446_Article Multisensory marketing (senses)_page-0001.png' 'transformed_shadows_alpha_IMG_3264_Article Multisensory marketing (senses)_page-0002.png' 'transformed_shadows_mult_IMG_3264_Article Multisensory marketing (senses)_page-0002.png' 'transformed_shadows_alpha_IMG_3266_report_finance.png' 'transformed_shadows_mult_IMG_3266_report_finance.png' ../crumpled_results/"
      ],
      "metadata": {
        "id": "6WrLSUwCxs_N"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fiva3awwpIU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Нумерация 2"
      ],
      "metadata": {
        "id": "GoqqMuW3pJLa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JV-1MIh1brdq"
      },
      "outputs": [],
      "source": [
        "FILENAME = 'IMG_1443.png'\n",
        "FILEBASENAME = FILENAME.split('.')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rLgJTptAhYcb"
      },
      "outputs": [],
      "source": [
        "img = cv.imread(path.join(SAMPLES_FOLDER, FILENAME))\n",
        "\n",
        "if img.shape[0] < img.shape[1]:\n",
        "  img = cv.rotate(img, cv.cv2.ROTATE_90_CLOCKWISE)\n",
        "  cv.imwrite(path.join(SAMPLES_FOLDER, FILENAME), img)\n",
        "\n",
        "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "img_blur = cv.GaussianBlur(img_gray, (15, 15), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61SpplJEm376"
      },
      "outputs": [],
      "source": [
        "surf = cv.xfeatures2d.SURF_create(hessianThreshold=1500, upright=True)\n",
        "kp, des = surf.detectAndCompute(img_blur, None)\n",
        "\n",
        "new_kp, indices = delete_similar_key_points(kp, iou_threshold=0.2)\n",
        "new_des = des[indices]\n",
        "\n",
        "circle_kp_des = sorted(list(zip(new_kp, new_des)), key=lambda x: np.linalg.norm(x[1] - reference_circle_des))\n",
        "circle_kp = [x[0] for x in circle_kp_des][:N_DOTS_ROW * N_DOTS_COL]\n",
        "circle_des = [x[1] for x in circle_kp_des][:N_DOTS_ROW * N_DOTS_COL]\n",
        "\n",
        "img_surf = cv.drawKeypoints(img, circle_kp, None, (255, 0, 0), 4)\n",
        "cv2_imshow(reduce_in_size(img_surf, 4))\n",
        "\n",
        "cv.imwrite(f'{RESULTS_FOLDER}/detected_{FILEBASENAME}.png', img_surf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3yEALmngpw2"
      },
      "outputs": [],
      "source": [
        "# thresh = cv.adaptiveThreshold(img_blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 77, -10)\n",
        "thresh = cv.threshold(img_blur, 0, 255, cv.THRESH_BINARY+cv.THRESH_OTSU)[1]\n",
        "\n",
        "kernel = np.ones((7,7), np.uint8)\n",
        "morph = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel)\n",
        "morph = cv.morphologyEx(morph, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "contours = cv.findContours(morph, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "big_contour = max(contours, key=cv.contourArea)\n",
        "\n",
        "countour_img = img.copy()\n",
        "countour_img = cv.drawContours(countour_img, [big_contour], 0, (0,255,0), 3)\n",
        "cv2_imshow(reduce_in_size(countour_img, 4))\n",
        "\n",
        "# cv.imwrite(f'{RESULTS_FOLDER}/countour_{FILEBASENAME}.png', countour_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EUZZjI9wpiMT"
      },
      "outputs": [],
      "source": [
        "# border_points = sorted(circle_kp, key=lambda x: cv.pointPolygonTest(big_contour, x.pt, True))\n",
        "\n",
        "# img_surf = img_gray.copy()\n",
        "# img_surf = cv.drawKeypoints(img_surf, border_points[:N_DOTS_ROW * 2 + N_DOTS_COL * 2 - 4], None, (0, 0, 255), 4)\n",
        "# cv2_imshow(cv.resize(img_surf, (rint(img_surf.shape[1] / 3), \n",
        "#                                 rint(img_surf.shape[0] / 3))))\n",
        "\n",
        "# border_points = set(border_points[:N_DOTS_ROW * 2 + N_DOTS_COL * 2 - 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRIYxajIDOCX"
      },
      "outputs": [],
      "source": [
        "# get perimeter and approximate a polygon\n",
        "peri = cv.arcLength(big_contour, True)\n",
        "corners = cv.approxPolyDP(big_contour, 0.04 * peri, True)\n",
        "\n",
        "# draw polygon on input image from detected corners\n",
        "polygon = img.copy()\n",
        "cv.polylines(polygon, [corners], True, (0,0,255), 1, cv.LINE_AA)\n",
        "# Alternate: cv.drawContours(page,[corners],0,(0,0,255),1)\n",
        "\n",
        "corners = corners.squeeze()\n",
        "\n",
        "# They seem to be listed counter-clockwise from the top most corner\n",
        "# renumerate so that the left top is the first\n",
        "if np.linalg.norm(corners[0] - corners[1]) < np.linalg.norm(corners[2] - corners[1]):\n",
        "  corners = np.roll(corners, -1, axis=0)\n",
        "\n",
        "assert len(corners) == 4\n",
        "\n",
        "for i in range(4):\n",
        "  polygon = cv.putText(\n",
        "      polygon, \n",
        "      str(i), \n",
        "      tuple(rint(corners[i])), \n",
        "      cv.FONT_HERSHEY_SIMPLEX, \n",
        "      5,\n",
        "      (0, 255, 0), \n",
        "      3, \n",
        "      cv.LINE_AA)\n",
        "\n",
        "cv2_imshow(reduce_in_size(polygon, 4))\n",
        "cv.imwrite(f'{RESULTS_FOLDER}/polygon_{FILEBASENAME}.png', polygon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHm7PnQUM97f"
      },
      "source": [
        "* Первая точка левая верхняя\n",
        "* Если находимся в начале строки, то запоминаем где начинается следующая строка\n",
        "* Если находимся в конце строки, то переходим на начало строки\n",
        "* В других случаях находим следующую справа точку в строку и переходим в нее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3Ym1wKXkSEbv"
      },
      "outputs": [],
      "source": [
        "top_left_point = min(circle_kp, \n",
        "                     key=lambda x: \n",
        "                     np.linalg.norm(np.array(x.pt) - corners[0]))\n",
        "\n",
        "ordered_kp = np.empty((N_DOTS_COL, N_DOTS_ROW), dtype=cv.KeyPoint)\n",
        "ordered_kp[0][0] = top_left_point\n",
        "unvisited_kp = set(circle_kp)\n",
        "unvisited_kp.remove(top_left_point)\n",
        "\n",
        "\n",
        "img_ordered_markers = img.copy()\n",
        "\n",
        "\n",
        "for row in range(N_DOTS_COL):\n",
        "  for col in range(N_DOTS_ROW - 1):\n",
        "    current_point = ordered_kp[row][col]\n",
        "\n",
        "    if row == N_DOTS_COL - 1:\n",
        "      consider_n_neighbours = 1\n",
        "    elif col == 0 or col == 1:\n",
        "      consider_n_neighbours = 3\n",
        "    else:\n",
        "      consider_n_neighbours = 4\n",
        "\n",
        "    neighbours = sorted(unvisited_kp,\n",
        "                  key=lambda x: \n",
        "                  np.linalg.norm(\n",
        "                      np.array(x.pt) - np.array(current_point.pt))\n",
        "                  )[:consider_n_neighbours]\n",
        "\n",
        "    if col == 0 and row < N_DOTS_COL - 1:\n",
        "      ordered_kp[row + 1][0] = min(neighbours, \n",
        "                                    key=lambda x: (x.pt[0], -x.pt[1]))\n",
        "      unvisited_kp.remove(ordered_kp[row + 1][0])\n",
        "\n",
        "      img_ordered_markers = cv.arrowedLine(img_ordered_markers, \n",
        "                          rint(current_point.pt), \n",
        "                          rint(ordered_kp[row + 1][0].pt),\n",
        "                          (0, 0, 0), 2)\n",
        "      \n",
        "    \n",
        "    ordered_kp[row][col + 1] = min(neighbours, \n",
        "                                key=lambda x: (x.pt[1], -x.pt[0]))\n",
        "    unvisited_kp.remove(ordered_kp[row][col + 1])\n",
        "\n",
        "    img_ordered_markers = cv.arrowedLine(img_ordered_markers, \n",
        "                          rint(current_point.pt), \n",
        "                          rint(ordered_kp[row][col + 1].pt),\n",
        "                          (0, 0, 0), 2)\n",
        "\n",
        "for row in range(N_DOTS_COL):\n",
        "  for col in range(N_DOTS_ROW):\n",
        "      cv.putText(\n",
        "        img_ordered_markers, \n",
        "        f'{col}',\n",
        "        rint(ordered_kp[row][col].pt), \n",
        "        cv.FONT_HERSHEY_SIMPLEX, \n",
        "        1,\n",
        "        (255, 0, 0), \n",
        "        2,\n",
        "        cv.LINE_AA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2heUcXsy_MDd"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(reduce_in_size(img_ordered_markers, 4))\n",
        "cv.imwrite(f'{RESULTS_FOLDER}/ordered_{FILEBASENAME}.png', img_ordered_markers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "S0g9rWj_xhIG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTG_S8pn_hDm"
      },
      "source": [
        "# Удаление маркеров 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9Qzq5rlXBzSL"
      },
      "outputs": [],
      "source": [
        "mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
        "for kp in circle_kp:\n",
        "  mask = cv.circle(mask, rint(kp.pt), rint(kp.size / 2), (255, 255, 255), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfCRKzigCH3n"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(reduce_in_size(mask, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioSXO7q5OhIF"
      },
      "outputs": [],
      "source": [
        "inpainted = cv.inpaint(img, mask, 3, cv.INPAINT_TELEA)\n",
        "\n",
        "cv2_imshow(reduce_in_size(inpainted, 4))\n",
        "cv.imwrite(f'{RESULTS_FOLDER}/inpainted_{FILEBASENAME}.png', inpainted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyl4UzJ-E_yO"
      },
      "source": [
        "# Смятие документа 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Y97NRCKce0XP"
      },
      "outputs": [],
      "source": [
        "EDOCFILE = 'Article Multisensory marketing (senses)0001-1.png'\n",
        "EDOCBASENAME = EDOCFILE.split('.')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "nDwvSx3MOlM4"
      },
      "outputs": [],
      "source": [
        "edoc = cv.imread(path.join(SAMPLES_FOLDER, 'electronic_documents', EDOCFILE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "yQ4JeZcAns81"
      },
      "outputs": [],
      "source": [
        "edoc_height, edoc_width = edoc.shape[:2]\n",
        "photo_height, photo_width = img.shape[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "qdZGWE_YoKOd"
      },
      "outputs": [],
      "source": [
        "crumpled_grid = np.array(list(map(\n",
        "    lambda point_list: \n",
        "    np.array([point.pt for point in point_list]), \n",
        "    ordered_kp)))\n",
        "\n",
        "crumpled_grid[:, :, 1] *= edoc_height / photo_height\n",
        "crumpled_grid[:, :, 0] *= edoc_width / photo_width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "-z0IMt7jt921"
      },
      "outputs": [],
      "source": [
        "y_grid = np.linspace(0, edoc_height, N_DOTS_COL)\n",
        "x_grid = np.linspace(0, edoc_width, N_DOTS_ROW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "uKTKLXqHvR85"
      },
      "outputs": [],
      "source": [
        "# TODO: generate pairs faster!\n",
        "\n",
        "points = np.array([[x, y] for x in range(edoc_width) for y in range(edoc_height)])\n",
        "\n",
        "init_dot_positions = np.array([[x, y] for y in y_grid for x in x_grid])\n",
        "\n",
        "transformed_dot_positions =  crumpled_grid.reshape((-1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "TF0E1atwvBKF"
      },
      "outputs": [],
      "source": [
        "interpolated = interpolate.griddata(init_dot_positions, transformed_dot_positions, points, method='linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlnnAJMywYYi",
        "outputId": "e80db935-01dd-48d5-f4ce-8475f7bceb5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15493536/15493536 [07:27<00:00, 34593.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15493536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transformed_edoc = np.full((edoc_height, edoc_width, 3), 255, dtype=np.uint8)\n",
        "\n",
        "%timeit\n",
        "operated = 0\n",
        "for i in tqdm(range(len(points))):\n",
        "  if not np.isnan(interpolated[i]).any():\n",
        "    operated += 1\n",
        "    y = max(0, int(np.round(interpolated[i][1])))\n",
        "    y = min(y, edoc_height - 1)\n",
        "\n",
        "    x = max(0, int(np.round(interpolated[i][0])))\n",
        "    x = min(x, edoc_width - 1)\n",
        "    transformed_edoc[y, x, :] = edoc[points[i][1], points[i][0], :]\n",
        "\n",
        "print(operated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM0bAL5Tw-Fu"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(reduce_in_size(transformed_edoc, 2))\n",
        "cv.imwrite(f'{RESULTS_FOLDER}/transformed_{FILEBASENAME}_{EDOCBASENAME}_dpi_{PDF_DPI}.png', transformed_edoc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpdy2h_IxdUH"
      },
      "source": [
        "# Наложение освещения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "SRvyuDv_yT2Q"
      },
      "outputs": [],
      "source": [
        "paper_contour = np.zeros(inpainted.shape)\n",
        "paper_contour = cv.drawContours(paper_contour, [big_contour], 0, (1, 1, 1), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "-AJQUwMezGkV"
      },
      "outputs": [],
      "source": [
        "illumination = inpainted * paper_contour\n",
        "illumination = cv.resize(illumination, (edoc_width, edoc_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "L59U8ifn0aOl"
      },
      "outputs": [],
      "source": [
        "alpha = 0.6\n",
        "transformed_edoc_shadows = illumination * (1 - alpha) + transformed_edoc * alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjiqpGTbzAgV"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(reduce_in_size(transformed_edoc_shadows, 2))\n",
        "cv.imwrite(f'{RESULTS_FOLDER}/transformed_shadows_alpha_{FILEBASENAME}_dpi_{PDF_DPI}_{EDOCBASENAME}.png', transformed_edoc_shadows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "ZsJDpQVsfxNJ"
      },
      "outputs": [],
      "source": [
        "illumination_normalized = cv.normalize(illumination, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
        "transformed_edoc_shadows_mult = illumination_normalized * transformed_edoc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnDmScZ-fjra"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(reduce_in_size(transformed_edoc_shadows_mult, 2))\n",
        "cv.imwrite(f'{RESULTS_FOLDER}/transformed_shadows_mult_{FILEBASENAME}_dpi_{PDF_DPI}_{EDOCBASENAME}.png', transformed_edoc_shadows_mult)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2WHTIH4a82R"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBLN2B2_a9k2"
      },
      "source": [
        "# Результаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoomtazicfcS"
      },
      "outputs": [],
      "source": [
        "h, w = rint(np.array(edoc.shape[:2]) * 0.8)\n",
        "\n",
        "img_surf_res = cv.resize(img_surf, (w, h))\n",
        "img_ordered_markers_res = cv.resize(img_ordered_markers, (w, h))\n",
        "inpainted_res = cv.resize(inpainted, (w, h))\n",
        "\n",
        "edoc_res = cv.resize(edoc, (w, h))\n",
        "transformed_edoc_res = cv.resize(transformed_edoc, (w, h))\n",
        "transformed_edoc_shadows_res = cv.resize(transformed_edoc_shadows, (w, h))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5jKbPlpa_sT"
      },
      "outputs": [],
      "source": [
        "inpaint_res_stacked = np.hstack((img_surf_res, img_ordered_markers_res, inpainted_res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7Y9tYEhiHT4"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(inpaint_res_stacked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ap0SlVD9hbwK"
      },
      "outputs": [],
      "source": [
        "transformation_res_stacked = np.hstack((edoc_res, transformed_edoc_res, transformed_edoc_shadows_res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22Elk3TfSwBS"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(transformation_res_stacked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBTiiPtSh9xX"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(transformed_edoc_shadows_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGsnJFKjsM1j"
      },
      "outputs": [],
      "source": [
        "vstacked = np.vstack((inpaint_res_stacked, transformation_res_stacked))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn3xkkmCsTUw"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(vstacked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTneCITISwgj"
      },
      "source": [
        "# Нахождение границы листа"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXuaYQkNS1Gu"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "F-HY8OnGpvsN"
      ],
      "name": "DocumentDistortion Current.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMXUvjsNvLBfH6if+RmYmjI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}